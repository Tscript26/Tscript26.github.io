# MYSQL学习文档（面试方向）

# 1. MYSQL的索引结构，聚簇索引和非聚簇索引的区别?

## 1.1 索引结构
MYSQL的索引结构有B+树索引、哈希索引、全文索引等。
B+树索引是最常用的索引结构，它的特点是：
* 所有数据都存储在叶子节点，非叶子节点只存储索引。
* 叶子节点之间通过指针连接，形成一个有序链表。
* 非叶子节点之间也通过指针连接，形成一个有序链表。
* 非叶子节点的个数比叶子节点的个数少一个。
* 叶子节点的个数等于表中的记录数。
* 非叶子节点的个数等于表中的记录数除以每个非叶子节点的大小。
* 每个非叶子节点的大小等于每个索引的大小加上一个指针的大小。
* 每个叶子节点的大小等于每个记录的大小加上一个指针的大小。
* 每个叶子节点的指针指向记录的物理地址。
* 每个非叶子节点的指针指向叶子节点的物理地址。

## 1.2 聚簇索引和非聚簇索引的区别

聚簇索引和非聚簇索引的区别在于：
* 聚簇索引的叶子节点存储的是整行数据。
* 非聚簇索引的叶子节点存储的是主键值。
* 聚簇索引的查询效率高，因为不需要回表查询。
* 非聚簇索引的查询效率低，因为需要回表查询。

## 1.3 索引的类型
MYSQL的索引类型有主键索引、唯一索引、普通索引、全文索引等。
主键索引是一种特殊的唯一索引，它要求每个表只能有一个主键索引。主键索引的叶子节点存储的是整行数据，所以主键索引的查询效率高。
唯一索引要求索引列的值必须唯一，但是允许有空值。普通索引没有唯一性的限制，一个普通索引可以包含多个列。全文索引用于全文搜索，它的索引类型为FULLTEXT。

## 1.4 索引的使用场景
主键索引：主键索引是一种特殊的唯一索引，它要求每个表只能有一个主键索引。主键索引的叶子节点存储的是整行数据，所以主键索引的查询效率高。
唯一索引：唯一索引要求索引列的值必须唯一，但是允许有空值。唯一索引的查询效率高，因为它可以利用索引进行快速的唯一性检查。
普通索引：普通索引没有唯一性的限制，一个普通索引可以包含多个列。普通索引的查询效率低，因为它需要回表查询。
全文索引：全文索引用于全文搜索，它的索引类型为FULLTEXT。全文索引的查询效率高，因为它可以利用索引进行快速的全文搜索。

## 1.5 索引的优化
索引的优化包括：
* 选择合适的索引列。
* 避免使用通配符查询。
* 使用组合索引。
* 定期更新和维护索引。
* 避免在索引列上进行函数/计算/类型转换/字符串连接操作。

## 1.6 索引的注意事项
* 索引会占用磁盘空间，所以不要为了索引而索引。
* 索引会影响写操作的性能，所以不要在经常写的表上创建索引。
* 索引可以提高查询效率，但是会降低写操作的效率。

## 1.7 索引的最佳实践
* 选择最频繁查询的列作为索引。
* 避免对经常更新的表进行过多的索引创建和删除操作。
* 合理使用索引，避免索引失效。
* 定期清理不再需要的索引。

# 2. MYSQL有几种高可用方案？分别适用的场景？

## 2.1 主从复制
主从复制是 MYSQL 最基本的高可用方案，它的基本原理是：将一个主数据库的数据复制到多个从数据库上，当主数据库出现故障时，从数据库可以自动切换为主数据库，从而实现高可用。
主从复制的适用场景是：对数据一致性要求不高，但是对数据的实时性要求较高的场景。

## 2.2 读写分离
读写分离是指将主数据库的写操作和读操作分离，分别由主数据库和从数据库承担。
读写分离的适用场景是：对数据一致性要求较高，但是对数据的实时性要求不高的场景。
读写分离的实现原理是：主数据库负责写操作，从数据库负责读操作。当主数据库出现故障时，从数据库可以自动切换为主数据库，从而实现高可用。

## 2.3 哨兵模式
哨兵模式是指在主从复制的基础上，增加一个哨兵节点，哨兵节点的作用是监控主从节点的状态，当主节点出现故障时，哨兵节点会自动将从节点切换为主节点，从而实现高可用。
哨兵模式的适用场景是：对数据一致性要求较高，对数据的实时性要求较高的场景。

## 2.4 集群模式
集群模式是指将多个主数据库合并为一个集群，每个主数据库负责一部分数据，当一个主数据库出现故障时，其他主数据库可以自动接管故障主数据库的工作，从而实现高可用。
集群模式的适用场景是：对数据一致性要求较高，对数据的实时性要求较高，并且需要水平扩展的场景。

# 3. MYSQL的事务隔离级别，幻读和不可重复读的区别？

## 3.1 事务隔离级别
MYSQL的事务隔离级别有4个，分别是：读未提交、读已提交、可重复读、串行化。
* 读未提交(read uncommitted)：事务可以读取其他事务未提交的数据。
* 读已提交(read committed)：事务只能读取其他事务已提交的数据。
* 可重复读(repeatable read)：事务在执行期间无论其他事务是否更新了数据，都只能看到事务开始时的数据。
* 串行化(serializable)：事务在执行期间会对数据进行加锁，其他事务不能对数据进行读写操作。

## 3.2 幻读和不可重复读的区别
* 幻读：指在一个事务内读取到了别的事务插入的数据，导致前后读取不一致。
* 不可重复读：指在一个事务内读取到了别的事务更新的数据，导致前后读取不一致。

## 3.3 如何选择事务隔离级别,对并发性能的影响？
* 读未提交：性能高，但是数据不一致。
* 读已提交：性能低，但是数据一致。
* 可重复读：性能中等，但是数据一致。
* 串行化：性能低，但是数据一致。

## 3.4 如何选择事务隔离级别
* 对于对数据一致性要求不高的场景，可以选择读未提交或者读已提交。
* 对于对数据一致性要求较高的场景，可以选择可重复读或者串行化。
* 对于对数据一致性要求最高的场景，可以选择串行化。

## 3.5 事务的ACID属性？
* 原子性(Atomicity)：事务是一个不可分割的工作单位，事务中的操作要么都发生，要么都不发生。
* 一致性(Consistency)：事务必须使数据库从一个一致性状态变到另一个一致性状态。
* 隔离性(Isolation)：事务的隔离性是指一个事务的执行不能被其他事务干扰。
* 持久性(Durability)：事务一旦提交，它对数据库中数据的改变就是永久性的。

## 3.6 什么是ACID？
ACID是指数据库事务的四个属性：原子性、一致性、隔离性和持久性。
原子性(Atomicity)：事务是一个不可分割的工作单位，事务中的操作要么都发生，要么都不发生。
一致性(Consistency)：事务必须使数据库从一个一致性状态变到另一个一致性状态。
隔离性(Isolation)：事务的隔离性是指一个事务的执行不能被其他事务干扰。
持久性(Durability)：事务一旦提交，它对数据库中数据的改变就是永久性的。

## 3.7 如何实现事务的ACID属性？
* 原子性：通过 undo log 实现。
* 一致性：通过 MVCC 实现。
* 隔离性：通过锁机制实现。
* 持久性：通过 redo log 实现。

### 3.7.1 undo log是什么？如何实现原子性的？
undo log 是一种日志记录，用于记录事务的回滚信息。
当一个事务开始执行时，会为该事务创建一个 undo log 记录，用于记录该事务对数据库的修改。
如果该事务执行失败，需要回滚，就可以根据 undo log 记录，将数据库恢复到事务执行前的状态。

### 3.7.2 什么是MVCC？如何实现一致性的？
MVCC（多版本并发控制, Multi-Version Concurrency Control） 是 InnoDB 为提升并发性和读一致性实现的一种机制，用于实现事务的隔离性。
MVCC的基本原理是：在数据库中为每个数据行记录多个版本，每个版本都有一个版本号，版本号是递增的。
每行数据都有两个隐藏列：trx_id(创建事务ID),roll_pointer(指向undo log)
通过当前事务的ID和trx_id进行比较，判断当前版本是否对当前事务可见
实现了**快照读**而不是当前读。

### 3.7.3 什么是锁机制？如何实现隔离性？
MySQL使用锁机制来隔离并发事务之间的操作，确保数据一致性。
可以分成行级锁，表级锁，意向锁
行级锁：锁定特定记录，innoDB支持，粒度小，适合高并发。
表级锁：锁定整张表，MyISAM使用。
意向锁：事务在行加锁前，先加表级意向锁，避免冲突。
实现隔离性的方式：
InnoDB结合锁机制与MVCC，支持四种隔离级别，
例如可重复读，通过MVCC快照和行锁实现
* 快照读：事务在执行期间，读取的是事务开始前的快照数据，不会阻塞其他事务的读写操作。
* 当前读：事务在执行期间，读取的是最新的数据，会阻塞其他事务的读写操作。

### 3.7.4 什么是redo log? 如何实现持久性的？
redo log 是一种日志记录，用于记录事务的提交信息。
当一个事务提交时，会为该事务创建一个 redo log 记录，用于记录该事务对数据库的修改。
如果数据库发生故障，需要恢复数据，就可以根据 redo log 记录，将数据库恢复到最近一次提交的状态。
redo log包含了log buffer（内存）和log file(磁盘)
使用circular buffer (环形结构)。
包括两个部分：prepare log (准备提交) 和 commit log(提交)，两者结合进行判断。

# 4. 分库和分表，分表为什么要用停服这种操作？如果不停服可以怎么做？

## 4.1 分库
分库的基本原理是：将一个数据库的数据分成多个数据库，每个数据库的数据量较小，这样可以提高查询效率。
分库的适用场景是：对数据一致性要求较高，但是对数据的实时性要求较高，并且需要水平扩展的场景。
分库的实现原理是：在数据库中创建多个数据库，每个数据库的数据量较小，但是数据库的数量较多。
分库的注意事项是：分库之后，数据库之间的数据不能直接查询，需要通过代码进行关联查询。

## 4.2 分表
分表的基本原理是：将一个大表的数据分成多个小表，每个小表的数据量较小，这样可以提高查询效率。
分表的适用场景是：对数据一致性要求较高，但是对数据的实时性要求较高，并且需要水平扩展的场景。
分表的实现原理是：在数据库中创建多个表，每个表的数据量较小，但是表的数量较多。
分表的注意事项是：分表之后，表之间的数据不能直接查询，需要通过代码进行关联查询。

## 4.3 分库分表方案？
* 垂直分库：将一个数据库中的表按照业务模块分成多个数据库，每个数据库负责一个业务模块。
* 垂直分表：将一个表中的列按照业务模块分成多个表，每个表负责一个业务模块。
* 水平分库：将一个数据库中的数据分成多个数据库，每个数据库的数据量较小。
* 水平分表：将一个表中的数据分成多个表，每个表的数据量较小。

## 4.4 常见分库分表中间件
* MySQL Proxy
* ShardingSphere
* MyCAT
* Elasticsearch + Kibana
* MongoDB + Elasticsearch

(讲解一个例子，比方说mongoDB + Elasticsearch作为分库分表中间件，是怎么实现的？
mongoDB + Elasticsearch作为分库分表中间件，是通过将mongoDB中的数据同步到Elasticsearch中，然后通过Elasticsearch进行查询。
有什么好处？
* 1. 提高查询效率：将数据放到ES中，可以提高查询效率。
* 2. 支持复杂查询：ES支持复杂查询，比如全文搜索、范围查询、聚合查询等。
* 3. 支持分布式查询：ES支持分布式查询，即多个节点组成一个集群，可以支持大规模数据的查询。
)

## 4.5 分库分表可能遇到的问题
* 数据一致性问题：
* 性能问题：
* 运维问题：
* 事务问题：需要分布式事务管理。
* 跨库关联查询问题：
* ID问题：数据库被切分后，不能再依赖数据库自身的主键生成机制，最简单可以考虑UUID
* 分页问题：
* 跨分片排序问题：（后台加大pagesize处理？） 


## 4.6 分表的停服操作？如果不停服，怎么做？
分表的停服操作是指在进行分表之前，先停服，然后进行分表操作，分表完成之后，再重启服务，防止数据不一致。
不停服，可以分成五个步骤：
1. 编写代理层：加个开关（控制访问新的DAO还是旧的DAO，或者都是访问），灰度期间，还是访问老的DAO
2. 发版全量后，开启双写：即在旧表新增和修改的同时，也在新表新增和修改。通过日志或几下新表的ID的起始值，小于这个值的就是存量数据，这批数据就是要迁移的。
3. 把旧库迁移到新库：通过脚本把旧表里面的存量数据写入新库
4. 停读旧表改读新表：此时信标已经承载了所有读写业务，但是不要立刻停写旧表，保持双写一段时间
5. 稳定后，停写旧表：当读写新表进行了一段时间后，没有发生问题，就可以停写旧表了。




## 5. 索引?
索引（Index）是数据库中用于加速数据查询的数据结构，本质上是一种辅助数据结构，作用类似于书籍目录。
索引是从列值 ➜ 数据行位置的映射；
MySQL 中常用的索引底层结构为 B+ 树（默认 InnoDB）；
全文搜索使用 倒排索引（Inverted Index）；
索引占用额外空间，并增加写入成本，但能极大提升读取效率。

## 5.1. 索引的最大数量？
在 MySQL InnoDB 存储引擎中，一个表最多可以创建 64 个二级索引（secondary indexes），外加 1 个主键索引（primary index）。

| 场景编号 | SQL 查询条件                                                                                           | 推荐索引                                                       | 原因说明                            |
| ---- | -------------------------------------------------------------------------------------------------- | ---------------------------------------------------------- | ------------------------------- |
| ①    | `WHERE id = 100`                                                                                   | `CREATE INDEX idx_id (id)`                                 | 主键/唯一键自动建立索引；无需额外设计             |
| ②    | `WHERE name = 'Alice'`                                                                             | `CREATE INDEX idx_name (name)`                             | 单列等值查询；走 B+ 树索引                 |
| ③    | `WHERE age > 30`                                                                                   | `CREATE INDEX idx_age (age)`                               | 范围查询；支持索引范围扫描（Index Range Scan） |
| ④    | `WHERE status = 'active' AND created_at > '2023-01-01'`                                            | `CREATE INDEX idx_status_created (status, created_at)`     | 联合索引，先等值后范围                     |
| ⑤    | `WHERE created_at BETWEEN '2023-01-01' AND '2023-02-01' ORDER BY created_at DESC`                  | `CREATE INDEX idx_created_at (created_at)`                 | 同时支持**范围查询 + 排序**               |
| ⑥    | `WHERE email LIKE 'abc%'`                                                                          | `CREATE INDEX idx_email (email)`                           | 前缀匹配可以走索引                       |
| ⑦    | `WHERE email LIKE '%abc%'`                                                                         | ❌ 不建议                                                      | 前缀为 `%` 无法走 B+ 树索引              |
| ⑧    | `WHERE city = 'Beijing' AND age > 20 AND gender = 'male'`                                          | `CREATE INDEX idx_city_gender_age (city, gender, age)`     | 多条件组合，等值字段在前                    |
| ⑨    | `ORDER BY created_at DESC LIMIT 10`                                                                | `CREATE INDEX idx_created_at (created_at DESC)`            | 索引可以加速排序与分页                     |
| ⑩    | `WHERE user_id = ? AND is_deleted = 0`                                                             | `CREATE INDEX idx_user_del (user_id, is_deleted)`          | 常用于软删除字段优化                      |
| ⑪    | `SELECT COUNT(*) FROM orders WHERE status = 'success'`                                             | `CREATE INDEX idx_status (status)`                         | 覆盖索引可以避免回表                      |
| ⑫    | `SELECT id FROM orders WHERE user_id = 123 AND created_at > '2023-01-01' ORDER BY created_at DESC` | `CREATE INDEX idx_user_created (user_id, created_at DESC)` | 同时支持过滤 + 排序                     |




